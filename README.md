# Intern Plan: Cybersecurity RAG System using LLMs & Embeddings

This plan will outline a 9-week structured mentorship plan for an introduction to Retrieval-Augmented Generation (RAG) and Large Language Models. Aimed practical learning for vector search, backend development, and LLM/RAG application in InfoSec.

---

## Week-by-Week Plan

### Week 1 – Foundations of LLMs & RAG

**Goals:**
- Understand what LLMs are and how they work
- Learn about basics of transformers, embeddings, and RAG basics

**Topics:**
- What are LLMs? (GPT, Mistral, LLaMA)
- Tokenization and embeddings
- What is RAG and why it matters in InfoSec

**Resources:**
- Hugging Face [NLP Course](https://huggingface.co/learn/nlp-course/chapter1)
- "Transformer Language Model" [Link](https://www.youtube.com/watch?v=-QH8fRhqFHM)
- “Retrieval-Augmented Generation Explained” [RAG Video](https://youtu.be/5Y3a61o0jFQ?feature=shared)

---

...**more to be added here**

### Week 10 - Goal - Prototype

![image](https://github.com/user-attachments/assets/cbedec45-a711-4965-bd49-839017ebb7f8)
